Problem: 1757. Recyclable and Low Fat Products

Intuition:
This problem is straightforward, we only have to filter out the id of rows where
both low_fats and recyclable columns are set to 'Y'

Approach:
Simply extract the rows that meet the condition using WHERE statement

Solution:
SELECT product_id FROM Products
WHERE low_fats='Y' AND recyclable='Y';


Problem: 2356. Number of Unique Subjects Taught by Each Teacher

Intuition:
This problem needs us to compute the number of "unique" subjects told by each teacher.
When seeing the word "unique", we immediately come up with DISTINCT statement. Also,
because we want to compute for each teacher, we certainly have to use GROUP BY.

Approach:
Firstly, since we have to compute value for each teacher, we use `GROUP BY teacher_id`.
Next, as we can generate the unique subjects by `DISTINCT subject_id`. Then, we compute
the number by `COUNT(DISTINCT subject_id)`

Solution:
SELECT teacher_id, COUNT(distinct subject_id) as cnt FROM Teacher
GROUP BY teacher_id;


Problem: 1741. Find Total Time Spent by Each Employee

Intuition:
This problem needs us to compute the total time each employee spent in the office for 
each day. And when it comes to `each`, we immediately come up with GROUP BY statement.
And for total, we could use SUM.

Approach:
Firstly, as we have to compute based on employee and date, so we have to use `GROUP BY emp_id, event_day`.
Next, we can directly use aggregate function SUM as `SUM(out_time-in_time)`

Solution:
SELECT event_day as day, emp_id, SUM(out_time-in_time) as total_time FROM Employees
GROUP BY emp_id, event_day;


Problem: 1693. Daily Leads and Partners

Intuition: 
This problem needs us to compute the unique leads and partners for each date of each make
name. Surely, we come up with DISTINCT, GROUP BY, COUNT statements.

Approach:
Firstly, as we have to compute based on date and make name, we use `GROUP BY date_id, make_name`.
Next, we can filter out distinct valus of leads and partners using `DISTINCT lead_id` and 
`DISTINCT partner_id`. Eventually, we make use of aggregate function COUNT as `COUNT(DISTINCT lead_id)`
and `COUNT(DISTINCT partner_id)` to compute the results.

Solution:
SELECT date_id, make_name, COUNT(distinct lead_id) as unique_leads, COUNT(distinct partner_id) as unique_partners FROM DailySales
GROUP BY date_id, make_name


Problem: 1393. Capital Gain/Loss

Intuition:
This problem needs us to compute the total gain/loss for each stock. So we must have to separate 
buy operation and sell operation. Also, because we have to compute each stock respectively, we
have to use GROUP BY.

Approach:
One of the important thing to notice is that when computing total gain/loss, we don't have to care
about the order of trading under this circumstances. So the strategy becomes: total sell price - 
total sell price. Firstly, we gather the total sell price for each stock using 

	SELECT stock_name, SUM(price) as sell_total FROM Stocks
	WHERE operation='Sell'
	GROUP BY stock_name, operation

This would serve as a subquery. Next we do the same thing for total buy price

	SELECT stock_name, sum(price) as buy_total FROM Stocks
	WHERE operation='Buy'
	GROUP BY stock_name, operation
	
Once we have these two queries, we can join them and compute sell_total-buy_total

Solution:
SELECT s.stock_name, s.sell_total-SUM(price) as capital_gain_loss FROM Stocks as b
	INNER JOIN (
		SELECT stock_name, SUM(price) as sell_total FROM Stocks
		WHERE operation='Sell'
		GROUP BY stock_name, operation
    ) AS s ON b.stock_name = s.stock_name
WHERE operation='Buy'
GROUP BY stock_name, operation;

Modified Solution:
SELECT stock_name, 
	SUM(
		CASE WHEN operation = 'Buy' THEN
			-price
		ELSE
			price
		END
	) AS capital_gain_loss
FROM Stocks
GROUP BY stock_name;

Modified Solution Explained:
In the modified solution, instead of separating the buy and sell operation using subquery,
it makes use of CASE WHEN statement. This have the same results that subquery have, but it
prevents from creating another tables which take more time. And it makes the code more succinct.


Problem: 1795. Rearrange Products Table

Intuition:
When I first read this question, I found out that it's all about transpose. In programming language
like SAS, Python, and R, they all have great function to handle transpose directly. However, there
isn't such a function in MySQL, so we have to carefully create each column ourselves.

Approach:
Firstly, we notice that there're only 3 stores, so we can use `SELECT 'store1'` to create the
`store` column. Here, we can find out that running the statement `SELECT p.product_id, "store1" 
as store, p.store1 as price FROM Products as p` actually returns the result that we want for each
store. So our next task would be stacking them up. Here, we can use `UNION ALL`. Eventually, we 
use `WHERE` statement to filter out rows that contain None value

Solution:
SELECT * FROM (
	SELECT p.product_id, "store1" as store, p.store1 as price FROM Products as p
	UNION ALL
	SELECT p.product_id, "store2" as store, p.store2 as price FROM Products as p
	UNION ALL
	SELECT p.product_id, "store3" as store, p.store3 as price FROM Products as p
) as r
WHERE r.price != 'None';


Problem: 1683. Invalid Tweets

Intuition:
It's straight forward

Approach:
Consider using `LENGTH` statement

Solution:
SELECT tweet_id FROM Tweets
WHERE LENGTH(content) > 15;


Problem: 1587. Bank Account Summary II

Intuition:
It contains two tables, so we surely have to use join operation. And it wants to compute
the balance for each person, so the combined use of `GROUP BY` and `SUM` is necessary.

Approach:
First, we have to consider what kind of join we have to use. For this problem, we can use
both inner join or left join (table Transactions would be left table). However, in real
world scenarios, I think it's more preferred to use left join because there might contains 
transactions that doesn't match with the account name. Using left join would ensure that 
no transaction records lost. So firstly, we performed left join operation

	SELECT * FROM Transactions as t
	LEFT JOIN Users as u
	ON t.account = u.account

Next, we have to compute the total balance for each person, so the query becomes

	SELECT u.name, SUM(t.amount) as balance FROM Transactions as t
	LEFT JOIN Users as u
	ON t.account = u.account
	GROUP BY u.name

Eventually, we can filter the account that has balance>10000 using subquery

Solution:
SELECT r.name, r.balance FROM (
	SELECT u.name, SUM(t.amount) as balance FROM Transactions as t
	LEFT JOIN Users as u
	ON t.account = u.account
	GROUP BY u.name
) as r
WHERE balance > 10000;


Problem: 627. Swap Salary

Intuition:
This is a simple problem while it requires to use `UPDATE` statement. Also, 
for conditioning labelling, we consider using `CASE WHEN` statement

Solution:
UPDATE Salary
SET sex = (
	CASE sex 
    WHEN 'f' THEN 'm'
    WHEN 'm' THEN 'f'
    END);
	

Problem: 1378. Replace Employee ID With The Unique Identifier

Intuition:
It's a straightforward left join problem

Solution:
SELECT eu.unique_id, e.name FROM Employees as e
LEFT JOIN EmployeeUNI as eu
ON e.id = eu.id;


Problem: 1068. Product Sales Analysis I

Intuition:
It's a straightforward join operation problem. All we have to think is that 
what kind of join operation we have to implement. Since the problem requires
us to demonstrate the information of each sale_id, so we can perform left join
and treat Sales table as left table.

Solution:
SELECT p.product_name, s.year, s.price FROM Sales as s
LEFT JOIN Product as p
ON s.product_id = p.product_id;


Problem: 1179. Reformat Department Table

Intuition:
This is also again a problem related to transposing. When think of transposing 
problem, we would firstly consider `CASE WHEN` statement. And a tip for this 
problem is that to show the "single" value when `GROUP BY` is used, we can 
technically use `SUM` because `GROUP BY` statement requires an aggregate 
function

Approach:
Firstly, we have to create new column for each month, so we use 

	CASE month WHEN 'blahblahblah' THEN revenue ELSE null END
	
Next, since the problem requires us to calculate result for each month, we 
have to use 
	
	GROUP BY id
	
Here comes the importance of aggregate function

	SUM(CASE month WHEN 'blahblahblah' THEN revenue ELSE null END) AS 'blahblahblah_revenue'
	
Solution:
SELECT id,
	SUM(CASE month WHEN 'Jan' THEN revenue ELSE NULL END) AS Jan_Revenue,
    SUM(CASE month WHEN 'Feb' THEN revenue ELSE NULL END) AS Feb_Revenue,
    SUM(CASE month WHEN 'Mar' THEN revenue ELSE NULL END) AS Mar_Revenue,
    SUM(CASE month WHEN 'Apr' THEN revenue ELSE NULL END) AS Apr_Revenue,
    SUM(CASE month WHEN 'May' THEN revenue ELSE NULL END) AS May_Revenue,
    SUM(CASE month WHEN 'Jun' THEN revenue ELSE NULL END) AS Jun_Revenue,
    SUM(CASE month WHEN 'Jul' THEN revenue ELSE NULL END) AS Jul_Revenue,
    SUM(CASE month WHEN 'Aug' THEN revenue ELSE NULL END) AS Aug_Revenue,
    SUM(CASE month WHEN 'Sep' THEN revenue ELSE NULL END) AS Sep_Revenue,
    SUM(CASE month WHEN 'Oct' THEN revenue ELSE NULL END) AS Oct_Revenue,
    SUM(CASE month WHEN 'Nov' THEN revenue ELSE NULL END) AS Nov_Revenue,
    SUM(CASE month WHEN 'Dec' THEN revenue ELSE NULL END) AS Dec_Revenue
FROM Department
GROUP BY id;


Problem: 1890. The Latest Login in 2020

Intuition:
This problem asks us to filter out the latest login for each id in 2020. 
So the first solution we come up to mind my be the combination usage 
of `WHERE`, `ORDER BY`, `GROUP BY`, and `LIMIT` statements. However, it turns
out that MySQL doesn't support this kind of operation. After thorough search,
I've found that after MySQL8, there is a new window function called `ROW_NUMBER`
that supports this kind of operation.

Approach:
Firstly, we filter out the date that is not in the year of 2020

	SELECT *, FROM Logins
	WHERE time_stamp >= '2020-01-01 00:00:00' and time_stamp <= '2020-12-31 23:59:59'
	
Next, we use the statement `ROW_NUMBER` to order the time_stamp based on each id

	SELECT *,
		ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY time_stamp DESC) AS row_num
	FROM Logins
	WHERE time_stamp >= '2020-01-01 00:00:00' and time_stamp <= '2020-12-31 23:59:59'

This way, we can use this subquery result to filter out the latest login date for each
id.

Solution:
SELECT r.user_id, r.time_stamp AS last_stamp FROM(
	SELECT *,
		ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY time_stamp DESC) AS row_num
	FROM Logins
	WHERE time_stamp >= '2020-01-01 00:00:00' and time_stamp <= '2020-12-31 23:59:59'
) as r
WHERE r.row_num = 1;

Modified Solution:
SELECT user_id, MAX(time_stamp) AS last_stamp FROM Logins
WHERE YEAR(time_stamp) = '2020'
GROUP BY user_id;

Modified Solution Explained:
This solution basically has the same concept with mine, but it makes use of other statements
to make the code cleaner. First, it uses `YEAR` to filter out data in 2020. For another, it 
makes use of `MAX` aggregate function in place of `WHERE r.row_number = 1`


Problem: 1484. Group Sold Products By The Date
Intuition:
This is a problem with `GROUP_BY`, but the tricky one is that it has to concatenate the string.
After thorough research, it turns out that this is only a simple problem that makes use of 
`GROUP_CONCAT` statement.

Solution:
SELECT sell_date, 
	COUNT(DISTINCT product) AS num_sold, 
	GROUP_CONCAT(DISTINCT product order by product) AS products FROM Activities
GROUP BY sell_date;


Problem: 175. Combine Two Tables

Intuition:
This is a simple join problem. However, the worth-noticing part is that if a person doesn't have
address information, he/she should still appears on the table with NULL in his/her address column.
So the INNER JOIN operation doesn't work, as it will filters out people who don't have address 
information. As a result, we shoud use LEFT JOIN operation

Solution:
SELECT p.firstname, p.lastname, a.city, a.state FROM Person as p
LEFT JOIN Address as a
ON p.personId = a.personId;


Problem: 1148. Article Views I

Intuition:
The problem requires us to list all the authors that have at least view there own articles once,
so what we have to to is to list the rows that has the same author_id and viewer_id. The following
steps are trivial

Solution:
SELECT DISTINCT author_id AS id FROM Views
WHERE author_id=viewer_id
ORDER BY author_id ASC;


Problem: 577. Employee Bonus

Intuition:
The is a simple LEFT JOIN problem

Solution:
SELECT e.name, b.bonus FROM Employee as e
LEFT JOIN Bonus as b
ON e.empId=b.empId
WHERE b.bonus<1000 or b.bonus is NULL;


Problem: 511. Game Play Analysis I

Intuition:
A simple problem requires special use of `GROUP BY` and `MIN` statement

Solution:
SELECT player_id, MIN(event_date) AS first_login FROM Activity
GROUP BY player_id;


Problem: 620. Not Boring Movies

Intuition:
A simple proble. Just have to notice how to use % to filter out odd numbers

Solution:
SELECT * FROM cinema
WHERE id % 2 = 1 and description != 'boring'
ORDER BY rating DESC;


Problem: 608. Tree Node

Intuition:
This problem asks us to label the type of nodes of the tree. As there're three
types of nodes, we have to come up of a condition to put them in different categories.
We can then notice that a root must doesn't have parent, so it's parent's id must be
NULL. Next, a node would be an inner node if its id is one of the parent's id. Then
the remaining nodes are leaf node. Under this circumstances, since we have to check the 
condition for each row. We come up with `CASE WHEN` statement

Approach:
First, we can find root node by

	p_id = 'None'
	
Next, we can find inner node by

	id in (SELECT DISTINCT p_id from tree)
	
Eventually, we can use `CASE WHEN` to combine the results

Solution:
SELECT id,
	CASE
		WHEN p_id = 'None' THEN 'Root'
		WHEN id in (SELECT DISTINCT p_id from tree) THEN 'Inner'
		ELSE 'Leaf'
	END AS type
FROM Tree;


Problem: 610. Triangle Judgement

Intuition:
Simple, just have to know that three sides could form a triangle if and only if 
the sum of any two sides is greater than the third side

Solution:
SELECT *,
	CASE 
		WHEN x+y>z and x+z>y and y+z>x THEN 'Yes'
        ELSE 'No'
	END AS 'triangle'
FROM Triangle;

Modified Solution:
SELECT *,
	IF (x+y>z and x+z>y and y+z>x, 'Yes', 'No') AS 'triangle'
FROM Triangle;

Modified Solution Explained:
This solution makes use of the `IF` statement. It improves the codes' redability
and performance at the same time.
